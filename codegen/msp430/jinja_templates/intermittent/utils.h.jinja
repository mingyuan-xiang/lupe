#ifndef UTILS_H
#define UTILS_H

#include <libfixedAbstract/fixed.h>
#include <libmspdriver/driverlib.h>
#include <libmatAbstract/mat.h>
#include <libmsp/nv.h>
#include <stdint.h>
#include <libdsp/DSPLib.h>
#include <layers/include/intermittent.h>

#define MAX_DMA_SIZE {{ max_dma_size }}
{% if global_mem_buffer %}
#define LEA_SIZE {{ lea_size }}
/* As long as the size is smaller than LEA buffer size, we are good. */
#define INTERMITTENT_BUFFER_SIZE LEA_SIZE
{%- else %}
#define LEA_FLT_SIZE {{ lea_size }}
#define LEA_SRC_SIZE {{ lea_size }}
#define LEA_DST_SIZE {{ lea_size }}
#define LEA_TMP_SIZE {{ lea_size }}
/* As long as the size is smaller than LEA buffer size, we are good. */
#define INTERMITTENT_BUFFER_SIZE (LEA_FLT_SIZE + LEA_SRC_SIZE + LEA_DST_SIZE + LEA_TMP_SIZE)
{%- endif %}

#define LUPE_MIN 0x8000
#define LUPE_Q15_MAX 32766 // 2^15 - 2

#define MAKE_ALIGN_2(s) ((s) + ((s) & 0x1))

#define INTERMITTENT_STATUS_SIZE 8
#define MAGIC_NUMBER 42

extern __ro_nv uint16_t magic_num;
extern __ro_nv uint16_t intermittent_status[];
extern __ro_nv uint32_t reboot_counter;

extern __ro_hinv int16_t intermittent_buffer[INTERMITTENT_BUFFER_SIZE];

#define VOLATILE_WRITE(var, offset) { \
  __asm__ __volatile__ ( \
      "MOVX.W %0, &intermittent_status+%c1\n\t" \
      : \
      : "r" (var), "i" (GET_OFFSET(offset)) \
      : "memory" \
  ); \
}

#define DOUBLE_BUFFER_TRANSFER(val, offset, in_addr, out_addr, size) { \
  int16_t next = val; \
  DMA_makeTransfer(in_addr, (uintptr_t)intermittent_buffer, size); \
  next = next | DOUBLE_BUFFER_WRITE; \
  VOLATILE_WRITE(next, offset); \
  DMA_makeTransfer(in_addr, out_addr, size); \
  next = next & DOUBLE_BUFFER_COMPLETE; \
  VOLATILE_WRITE(next, offset); \
}

#define DOUBLE_BUFFER_ASSIGN(val, offset, in, out) { \
  int16_t next = val; \
  intermittent_buffer[0] = in; \
  next = next | DOUBLE_BUFFER_WRITE; \
  VOLATILE_WRITE(next, offset); \
  out = in; \
  next = next & DOUBLE_BUFFER_COMPLETE; \
  VOLATILE_WRITE(next, offset); \
}

/*
 * Reset a variable and transfer data with double buffer.
 * This is helpful for batched-FIR and point-wise MPY.
 */
#define DOUBLE_BUFFER_TRANSFER_WITH_VAR_RESET(val, offset, var, in_addr, out_addr, size) { \
  int16_t next = val; \
  DMA_makeTransfer(in_addr, (uintptr_t)intermittent_buffer, size); \
  next = next | DOUBLE_BUFFER_WRITE; \
  VOLATILE_WRITE(next, offset); \
  var = 0; \
  DMA_makeTransfer(in_addr, out_addr, size); \
  next = next & DOUBLE_BUFFER_COMPLETE; \
  VOLATILE_WRITE(next, offset); \
}

/*
 * Reset a large chunk of memory
 * `st` determines which intermittent_status is used
 */
void large_memset(_q15* reset_ptr, uint16_t total_size, uint16_t st);

/*
 * Transfer a large chunk of memory
 * `st` determines which intermittent_status is used
 */
void large_dma(uintptr_t in, uintptr_t out, uint16_t total_size, uint16_t st);

{% if global_mem_buffer %}
extern _q15 lea_buffer[];
{%- else %}
extern _q15 lea_flt[];
extern _q15 lea_src[];
extern _q15 lea_tmp[];
extern _q15 lea_dst[];
{%- endif %}
extern _iq31 lea_res[];

{% if lea_opt %}
extern MSP_LEA_ADDMATRIX_PARAMS* lea_add_params;
extern MSP_LEA_FIR_PARAMS* lea_fir_params;
extern MSP_LEA_MAC_PARAMS* lea_mac_params;
extern MSP_LEA_ADDMATRIX_PARAMS* lea_fill_params;
extern MSP_LEA_MPYMATRIX_PARAMS* lea_mpy_params;
extern int16_t* fill_vector;
extern uint16_t fill_vector_addr;
extern MSP_LEA_ADDMATRIX_PARAMS* lea_offset_params;
extern int16_t* offset_vector;
extern MSP_LEA_DEINTERLEAVE_PARAMS* lea_deinterleave_params;
extern uint16_t deinterleave_cmdId;
extern uint16_t deinterleave_channel;
extern MSP_LEA_MPYMATRIXROW_PARAMS* lea_vector_matrix_mpy_params;
{%- endif %}

#define GET_MAT_SIZE(mat) ((mat)->strides[0] * (mat)->dims[0])

{% if dma_opt %}
#define DMA_EN_SIG (DMAEN | DMAREQ)

#define _lupe_data16_write_addr(addr, src) ({ \
  uintptr_t __src = src; \
  __asm__  __volatile__ ("movx.a %1, %0\n\t" : "=m"(addr) : "r"(__src)); \
})

#define __lupe_data16_write_addr(addr, src) _lupe_data16_write_addr((addr), (src))

#define DMA_makeTransfer(src, dst, size) { \
  DMA0CTL = DMADT_1 | DMADSTINCR_3 | DMASRCINCR_3 | DMADSTBYTE__WORD | DMASRCBYTE__WORD | DMAIE; \
  __lupe_data16_write_addr((DMA0SA), (src)); \
  __lupe_data16_write_addr((DMA0DA), (dst)); \
  DMA0SZ = size; \
  uint16_t interruptState = __get_interrupt_state(); \
  __disable_interrupt(); \
  DMA0CTL |= DMA_EN_SIG; \
  __bis_SR_register(GIE + LPM0_bits); \
  __set_interrupt_state(interruptState); \
}

#define DMA_setWord(dst, word, size) { \
  DMA1CTL = DMADT_1 | DMADSTINCR_3 | DMASRCINCR_0 | DMADSTBYTE__WORD | DMASRCBYTE__WORD | DMAIE; \
  __lupe_data16_write_addr((DMA1SA), ((uintptr_t)(&word))); \
  __lupe_data16_write_addr((DMA1DA), (dst)); \
  DMA1SZ = size; \
  uint16_t interruptState = __get_interrupt_state(); \
  __disable_interrupt(); \
  DMA1CTL |= DMA_EN_SIG; \
  __bis_SR_register(GIE + LPM0_bits); \
  __set_interrupt_state(interruptState); \
}
{% else %}
#define DMA_makeTransfer(src, dst, size) {\
  DMA_setTransferSize(DMA_CHANNEL_0, size); \
  DMA_setSrcAddress(DMA_CHANNEL_0, src, DMA_DIRECTION_INCREMENT); \
  DMA_setDstAddress(DMA_CHANNEL_0, dst, DMA_DIRECTION_INCREMENT); \
  DMA_enableTransfers(DMA_CHANNEL_0); \
  uint16_t interruptState = __get_interrupt_state(); \
  __disable_interrupt(); \
  DMA_startTransfer(DMA_CHANNEL_0); \
  __bis_SR_register(GIE + LPM0_bits); \
  __set_interrupt_state(interruptState); \
}
{%- endif %}

{% if lea_opt %}
void add_init(uint16_t length);

void fir_init(uint16_t length, uint16_t tapLength);

void mac_init(uint16_t length);

void offset_init(uint16_t length);

void fill_init(uint16_t length);

void mpy_init(uint16_t length);

void deinterleave_init(uint16_t length, uint16_t channel, uint16_t numChannels);

void vector_matrix_mpy_init(uint16_t mat_row, uint16_t mat_col);

void add_clear();

void fir_clear();

void mac_clear();

void offset_clear();

void fill_clear();

void mpy_clear();

void deinterleave_clear();

void vector_matrix_mpy_clear();
{%- endif %}

void init_lupe();

#endif