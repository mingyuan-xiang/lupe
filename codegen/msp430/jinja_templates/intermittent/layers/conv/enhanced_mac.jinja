/*
 * _LEA_SRC_SIZE will always be mutiple of _FLT_LEN
 * so that _LEA_REMAIN_SIZE will always be multiple of _FLT_LEN.
 */
#define _KERNEL_ROW_SIZE {{ flt_size }}
#define _KERNEL_COL_SIZE {{ flt_col_size }}
#define _FLT_LEN (_KERNEL_ROW_SIZE * _KERNEL_COL_SIZE)
#define __LEA_SRC_SIZE {{ lea_src_size }}
#define _LEA_SRC_SIZE (__LEA_SRC_SIZE - (__LEA_SRC_SIZE % _FLT_LEN))
#define _IN_CHANNEL_NUM {{ in_ch }}
#define _MAC_LEN (_FLT_LEN * _IN_CHANNEL_NUM)
#define _LEA_REMAIN_SIZE (_MAC_LEN % _LEA_SRC_SIZE)
#define _LEA_REMAIN_SIZE_CHANNEL_CNT (_LEA_REMAIN_SIZE / _FLT_LEN)
#define _LEA_SRC_SIZE_CHANNEL_CNT (_LEA_SRC_SIZE / _FLT_LEN)
{% if global_mem_buffer %}
#define _LEA_ADD_SIZE {{ lea_buffer_size }}
{%- else %}
#define _LEA_ADD_SIZE {{ lea_src_size }}
{% endif %}
#define _LEA_ADD_REMAIN_SIZE ({{ out_len }} % _LEA_ADD_SIZE)
{% if padding %}
#define _PADDING_TOP {{ padding["top"] }}
#define _PADDING_BOTTOM {{ padding["bottom"] }}
#define _PADDING_RIGHT {{ padding["right"] }}
#define _PADDING_LEFT {{ padding["left"] }}
{%- endif %}
{% if global_mem_buffer %}
/* assign the lea buffer pointer */
#define lea_src (lea_buffer)
#define lea_flt (lea_buffer + {{ lea_src_size }})
#define lea_tmp (lea_buffer + {{ lea_src_size + lea_flt_size }})
#define lea_dst (lea_buffer + {{ lea_src_size + lea_flt_size + lea_tmp_size }})
{% endif %}
#define _INPUT_LINE_SIZE {{ in_line_size }}
#define _STRIDE_ROW_SIZE {{ stride_row }}
#define _STRIDE_COL_SIZE {{ stride_col }}
#define _STRIDE_COL_OFFSET (_STRIDE_COL_SIZE * sizeof(int16_t))
{% if lea_opt %}
static inline __attribute__((always_inline)) void new_mac_q15(const _q15 *srcA, const _q15 *srcB) {
  lea_mac_params->input2 = MSP_LEA_CONVERT_ADDRESS(srcB);

  /* Load source arguments to LEA. */
  LEAPMS0 = MSP_LEA_CONVERT_ADDRESS(srcA);
  LEAPMS1 = MSP_LEA_CONVERT_ADDRESS(lea_mac_params);

  /* Invoke the LEACMD__MAC command. */
  msp_lea_invokeCommand(LEACMD__MAC);
}

static inline __attribute__((always_inline)) void new_add_q15(const _q15* srcA, const _q15* srcB, _q15* dst) {
  lea_add_params->input2 = MSP_LEA_CONVERT_ADDRESS(srcB);
  lea_add_params->output = MSP_LEA_CONVERT_ADDRESS(dst);

  /* Load source arguments to LEA. */
  LEAPMS0 = MSP_LEA_CONVERT_ADDRESS(srcA);
  LEAPMS1 = MSP_LEA_CONVERT_ADDRESS(lea_add_params);

  /* Invoke the LEACMD__ADDMATRIX command. */
  msp_lea_invokeCommand(LEACMD__ADDMATRIX);
}

static inline __attribute__((always_inline)) void set_offset(int16_t offset) {
  offset_vector[0] = offset;
  offset_vector[1] = offset;
}

static inline __attribute__((always_inline)) void new_offset_q15(const _q15* src, _q15* dst) {
  lea_offset_params->output = MSP_LEA_CONVERT_ADDRESS(dst);

  /* Load source arguments to LEA. */
  LEAPMS0 = MSP_LEA_CONVERT_ADDRESS(src);
  LEAPMS1 = MSP_LEA_CONVERT_ADDRESS(lea_offset_params);

  /* Invoke the LEACMD__ADDMATRIX command. */
  msp_lea_invokeCommand(LEACMD__ADDMATRIX);
}
{%- endif %}

void {{ layer_name }}(mat_t* input, mat_t* output, mat_t* weight, mat_t* bias) {
  {%- if padding %}
  uint16_t in_channels = input->dims[1];
  {%- endif %}
  uint16_t out_channels = output->dims[1];
  uint16_t output_len = output->strides[1];
  uint16_t input_len = input->strides[1];
  uint16_t kernel_row_size = _KERNEL_ROW_SIZE;
  uint16_t kernel_col_size = _KERNEL_COL_SIZE;

  uintptr_t flt_lea_addr = (uintptr_t)lea_flt;
  uintptr_t flt_fram_addr = (uintptr_t)(weight->data);
  {%- if (in_ch_flt_len % (lea_src_size - (lea_src_size % flt_len))) != 0 %}
  uintptr_t mac_size = _LEA_REMAIN_SIZE;
  {%- else %}
  uintptr_t mac_size = _LEA_SRC_SIZE;
  {%- endif %}
  {%- if (in_ch_flt_len % (lea_src_size - (lea_src_size % flt_len))) != 0 %}
  uintptr_t flt_channel_remain_offset = _LEA_REMAIN_SIZE * sizeof(int16_t);
  {%- endif %}
  uintptr_t flt_channel_src_offset = _LEA_SRC_SIZE * sizeof(int16_t);
  uintptr_t flt_channel_offset = weight->strides[0] * sizeof(int16_t);
  uintptr_t flt_addr_col_offset = kernel_col_size * sizeof(int16_t);
  uintptr_t input_fram_addr = (uintptr_t)(input->data);
  uintptr_t input_channel_offset = input_len * sizeof(int16_t);
  uintptr_t lea_src_addr = (uintptr_t)lea_src;

  uint16_t lea_mac_remain_size_aligned = MAKE_ALIGN_2(_LEA_REMAIN_SIZE);
  {%- if in_ch_flt_len >= (lea_src_size - (lea_src_size % flt_len)) %}
  uint16_t lea_mac_size_aligned = MAKE_ALIGN_2(_LEA_SRC_SIZE);
  {%- endif %}

  uint16_t input_line_size = input->dims[3];
  uint16_t output_line_size = output->dims[3];
  uint16_t output_line_num = output->dims[2];
  uint16_t input_line_size_offset = input_line_size * sizeof(int16_t);
  uint16_t input_line_strided_size = input_line_size * _STRIDE_ROW_SIZE;
  uint16_t input_line_size_strided_offset = input_line_strided_size * sizeof(int16_t);

  uint16_t lea_remain_size = _LEA_ADD_REMAIN_SIZE;
  {%- if (global_mem_buffer and (out_len % lea_buffer_size) != 0) or ((not global_mem_buffer) and (out_len % lea_src_size) != 0) %}
  uintptr_t output_remain_size_offset = lea_remain_size * sizeof(int16_t);
  {%- endif %}
  {%- if (global_mem_buffer and out_len >= lea_buffer_size) or ((not global_mem_buffer) and out_len >= lea_src_size) %}
  uintptr_t output_lea_min_size_offset = _LEA_ADD_SIZE * sizeof(int16_t);
  {%- endif %}
  uint16_t lea_remain_size_aligned = MAKE_ALIGN_2(lea_remain_size);

  {%- if lea_opt %}
  {%- if (in_ch_flt_len % (lea_src_size - (lea_src_size % flt_len))) != 0 %}
  mac_init(lea_mac_remain_size_aligned);
  {%- else %}
  mac_init(lea_mac_size_aligned);
  {%- endif %}
  add_init(lea_remain_size_aligned);
  offset_init(lea_remain_size_aligned);

  {%- else %}
  {%- if (in_ch_flt_len % (lea_src_size - (lea_src_size % flt_len))) != 0 %}
  msp_mac_q15_params mac_params = { .length = lea_mac_remain_size_aligned };
  {%- else %}
  msp_mac_q15_params mac_params = { .length = lea_mac_size_aligned };
  {%- endif %}
  msp_add_q15_params add_params = { .length = lea_remain_size_aligned };
  msp_offset_q15_params offset_params = { .length = lea_remain_size_aligned, .offset = 0 };
  {%- endif %}
  {%- if has_adaptive_gen_mem %}
  uint16_t s;
  {%- if flt_col_size < adaptive_gen_mem_size %}
  uint16_t input_fram_pos = 0;
  {%- endif %}
  {%- endif %}

  {%- if dma_opt and padding %}
  uint16_t zero = 0;
  {%- endif %}

  uintptr_t intermittent_buffer_addr = (uintptr_t)intermittent_buffer;
  uintptr_t intermittent_mac_buffer_addr = intermittent_buffer_addr + sizeof(int16_t);

  /* No need for double buffering (for loop indices) as each output is independent */
  if (intermittent_status[COMPUTE_CK] == INTERMITTENT_{{ layer_name }}_PREPARE) {
    {%- if dma_opt or padding %}
    uintptr_t output_fram_addr = (uintptr_t)(output->data);
    {%- endif %}
    switch (intermittent_status[COMPUTE_SWITCH]) {
    case PAD_START: {
    {%- if padding %}
      large_memset(output->data, GET_MAT_SIZE(input), COMPUTE_IO_COL);
      VOLATILE_WRITE(PAD_MAIN, COMPUTE_SWITCH);
    }
    case PAD_MAIN: {
    /* Pad the input for ({{ padding["left"] }}, {{ padding["right"] }}, {{ padding["top"] }}, {{ padding["bottom"] }}) */
      uint16_t input_line_num = input->dims[2] - _PADDING_TOP - _PADDING_BOTTOM;
      uint16_t input_line_size_bf = input->dims[3] - _PADDING_RIGHT - _PADDING_LEFT;
      uint16_t input_len_bf = input_line_num * input_line_size_bf;

      if (intermittent_status[COMPUTE_IO_ROW] >= input_line_num) {
        VOLATILE_WRITE(0, COMPUTE_IO_ROW);
        uint16_t next_i = intermittent_status[COMPUTE_IN_CH] + 1;
        VOLATILE_WRITE(next_i, COMPUTE_IN_CH);
      }

      _q15* padding_ptr_in = input->data + \
        intermittent_status[COMPUTE_IN_CH] * input_len_bf + \
        intermittent_status[COMPUTE_IO_ROW] * input_line_size_bf;
      _q15* padding_ptr_out = output->data + \
        intermittent_status[COMPUTE_IN_CH] * input_len + \
        intermittent_status[COMPUTE_IO_ROW] * input_line_size;

      for (uint16_t i = intermittent_status[COMPUTE_IN_CH]; i < in_channels; ++i) {
        {%- for n in range(padding["top"]) %}
        padding_ptr_out += input_line_size;
        {%- endfor %}
        for (uint16_t j = intermittent_status[COMPUTE_IO_ROW]; j < input_line_num; ++j) {
          padding_ptr_out += _PADDING_LEFT;
          {%- if has_adaptive_gen_mem and (in_line_size - padding["left"] - padding["right"] < adaptive_gen_mem_size) %}
          {%- for n in range(in_line_size - padding["left"] - padding["right"]) %}
          *padding_ptr_out = *padding_ptr_in;
          ++padding_ptr_out;
          ++padding_ptr_in;
          {%- endfor %}

          padding_ptr_out += _PADDING_RIGHT;
          {%- else %}
          DMA_makeTransfer((uintptr_t)padding_ptr_in, (uintptr_t)padding_ptr_out, input_line_size_bf);
          padding_ptr_in += input_line_size_bf;
          padding_ptr_out += (_PADDING_RIGHT + input_line_size_bf);
          {%- endif %}

          intermittent_status[COMPUTE_IO_ROW]++;
        }
        {%- for n in range(padding["bottom"]) %}
        padding_ptr_out += input_line_size;
        {%- endfor %}

        VOLATILE_WRITE(0, COMPUTE_IO_ROW);
        uint16_t next_i = i + 1;
        VOLATILE_WRITE(next_i, COMPUTE_IN_CH);
      }

      VOLATILE_WRITE(PAD_TRANSFER, COMPUTE_SWITCH);
    }
    case PAD_TRANSFER: {
      large_dma(output_fram_addr, input_fram_addr, GET_MAT_SIZE(input), COMPUTE_OUT_CH);

      VOLATILE_WRITE(PAD_MEMSET, COMPUTE_SWITCH);
    }
    case PAD_MEMSET:
      /* intermittent_status[COMPUTE_IO_ROW] should be zero right now */
      large_memset(output->data, GET_MAT_SIZE(output), COMPUTE_IO_ROW);
      VOLATILE_WRITE(PAD_ST_RESET, COMPUTE_SWITCH);
    case PAD_ST_RESET:
      VOLATILE_WRITE(0, COMPUTE_IO_COL);
      VOLATILE_WRITE(0, COMPUTE_IO_ROW);
      VOLATILE_WRITE(0, COMPUTE_IN_CH);
      VOLATILE_WRITE(0, COMPUTE_OUT_CH);
    {%- else %} {# not padding #}
      large_memset(output->data, GET_MAT_SIZE(output), COMPUTE_IO_COL);
      VOLATILE_WRITE(PAD_ST_RESET, COMPUTE_SWITCH);
    }
    case PAD_ST_RESET:
      VOLATILE_WRITE(0, COMPUTE_IO_COL);
    {%- endif %} 
      VOLATILE_WRITE(PAD_END, COMPUTE_SWITCH);
    default:
      break;
    }

    VOLATILE_WRITE(INTERMITTENT_{{ layer_name }}_MAIN, COMPUTE_CK);
  }

  /* convolution */
  if (intermittent_status[COMPUTE_CK] == INTERMITTENT_{{ layer_name }}_MAIN) {
    if (intermittent_status[COMPUTE_IN_CH] & DOUBLE_BUFFER_WRITE) {
      uint16_t idx = intermittent_status[COMPUTE_IN_CH] & DOUBLE_BUFFER_COMPLETE;
      VOLATILE_WRITE(MAC_PREPARE, COMPUTE_SWITCH);
      VOLATILE_WRITE(idx, COMPUTE_IN_CH);
    }

    if (intermittent_status[COMPUTE_IO_COL] & DOUBLE_BUFFER_WRITE) {
      uint16_t idx = intermittent_status[COMPUTE_IO_COL] & DOUBLE_BUFFER_COMPLETE;
      VOLATILE_WRITE(intermittent_buffer[0], COMPUTE_IN_CH);
      VOLATILE_WRITE(idx, COMPUTE_IO_COL);
    }

    if (intermittent_status[COMPUTE_IO_ROW] & DOUBLE_BUFFER_WRITE) {
      uint16_t idx = intermittent_status[COMPUTE_IO_ROW] & DOUBLE_BUFFER_COMPLETE;
      VOLATILE_WRITE(intermittent_buffer[0], COMPUTE_IO_COL);
      VOLATILE_WRITE(idx, COMPUTE_IO_ROW);
    }

    if (intermittent_status[COMPUTE_SWITCH] == MAC_COMPUTE) {
      if (intermittent_status[COMPUTE_OUT_CH] & DOUBLE_BUFFER_WRITE) {
        uint16_t idx = intermittent_status[COMPUTE_OUT_CH] & DOUBLE_BUFFER_COMPLETE;
        uint16_t pos = intermittent_status[COMPUTE_IO_ROW] * output_line_size + \
          intermittent_status[COMPUTE_IO_COL] + (idx - 1) * output_len;
        output->data[pos] = intermittent_buffer[0];
        VOLATILE_WRITE(idx, COMPUTE_OUT_CH);
      }

      if (intermittent_status[COMPUTE_OUT_CH] >= out_channels) {
        VOLATILE_WRITE(MAC_END, COMPUTE_SWITCH);
      } else {
        {%- if (in_ch_flt_len % (lea_src_size - (lea_src_size % flt_len))) != 0 %}
        uint16_t size = _LEA_REMAIN_SIZE;
        if (intermittent_status[COMPUTE_IN_CH] != 0) {
          size = _LEA_SRC_SIZE;
        }
        {%- else %}
        uint16_t size = _LEA_SRC_SIZE;
        {%- endif %}

        DMA_makeTransfer(intermittent_mac_buffer_addr, lea_src_addr, size);
      }
    }

    if (intermittent_status[COMPUTE_IN_CH] >= _MAC_LEN) {
      uint16_t next_idx = intermittent_status[COMPUTE_IO_COL] + 1;
      DOUBLE_BUFFER_ASSIGN(next_idx, COMPUTE_IO_COL, 0, intermittent_status[COMPUTE_IN_CH]);
    }

    if (intermittent_status[COMPUTE_IO_COL] >= output_line_size) {
      uint16_t next_idx = intermittent_status[COMPUTE_IO_ROW] + 1;
      DOUBLE_BUFFER_ASSIGN(next_idx, COMPUTE_IO_ROW, 0, intermittent_status[COMPUTE_IO_COL]);
    }

    uint16_t out_pos = intermittent_status[COMPUTE_IO_ROW] * output_line_size + \
      intermittent_status[COMPUTE_IO_COL];
    uint16_t tmp_out_pos;
    {%- if has_adaptive_gen_mem and flt_col_size < adaptive_gen_mem_size %}
    input_fram_pos = intermittent_status[COMPUTE_IO_ROW] * input_line_strided_size;
    {%- else %}
    input_fram_addr += intermittent_status[COMPUTE_IO_ROW] * input_line_size_strided_offset;
    {%- endif %}

    for (uint16_t m = intermittent_status[COMPUTE_IO_ROW]; m < output_line_num; ++m) {
      {%- if has_adaptive_gen_mem and flt_col_size < adaptive_gen_mem_size %}
      uint16_t tmp_input_pos = input_fram_pos + intermittent_status[COMPUTE_IO_COL] * _STRIDE_COL_SIZE;
      {%- else %}
      uintptr_t tmp_input_addr = input_fram_addr + intermittent_status[COMPUTE_IO_COL] * _STRIDE_COL_OFFSET;
      {%- endif %}
      for (uint16_t n = intermittent_status[COMPUTE_IO_COL]; n < output_line_size; ++n) {
        /* Use intermittent_buffer to hold reshaped input */
        {%- if has_adaptive_gen_mem and flt_col_size < adaptive_gen_mem_size %}
        uint16_t mac_buffer_pos = 0;
        {%- else %}
        uintptr_t mac_buffer_addr = lea_src_addr;
        {%- endif %}
        uintptr_t flt_tmp_addr = flt_fram_addr + intermittent_status[COMPUTE_IN_CH] * sizeof(int16_t);
        {%- if has_adaptive_gen_mem and flt_col_size < adaptive_gen_mem_size %}
        uint16_t input_offset = 0;
        {%- else %}
        uintptr_t input_offset = 0;
        {%- endif %}

  /*************************************************************
  * Do the reminder of MAC first
  ************************************************************/
        {%- if in_ch_flt_len > (lea_src_size - (lea_src_size % flt_len)) %}
        if (intermittent_status[COMPUTE_IN_CH] == 0) {
        {%- endif %}
          if (intermittent_status[COMPUTE_SWITCH] == MAC_COMPUTE) {
            {%- if has_adaptive_gen_mem and flt_col_size < adaptive_gen_mem_size %}
            {%- if (in_ch_flt_len % (lea_src_size - (lea_src_size % flt_len))) != 0 %}
            input_offset = input_len * _LEA_REMAIN_SIZE_CHANNEL_CNT;
            {%- else %}
            input_offset = input_len * _LEA_SRC_SIZE_CHANNEL_CNT;
            {%- endif %}

            {%- else %} {# not has_adaptive_gen_mem and flt_col_size < adaptive_gen_mem_size #}

            {%- if (in_ch_flt_len % (lea_src_size - (lea_src_size % flt_len))) != 0 %}
            input_offset = input_channel_offset * _LEA_REMAIN_SIZE_CHANNEL_CNT;
            {%- else %}
            input_offset = input_channel_offset * _LEA_SRC_SIZE_CHANNEL_CNT;
            {%- endif %}
            {%- endif %}
          }

          {%- if has_adaptive_gen_mem and flt_col_size < adaptive_gen_mem_size %}
          uint16_t tmp_channel_pos = tmp_input_pos + input_offset;
          {%- else %}
          uintptr_t tmp_channel_addr = tmp_input_addr + input_offset;
          {%- endif %}
          uintptr_t flt_mac_addr = flt_tmp_addr + intermittent_status[COMPUTE_OUT_CH] * flt_channel_offset;
          {%- if (in_ch_flt_len % (lea_src_size - (lea_src_size % flt_len))) != 0 %}
          {%- if (in_ch_flt_len % (lea_src_size - (lea_src_size % flt_len))) % 2 != 0 %}
          /* set the aligned position to be zeros */
          lea_src[_LEA_REMAIN_SIZE] = 0;
          lea_flt[_LEA_REMAIN_SIZE] = 0;
          {%- endif %}
          {%- else %}
          {%- if (lea_src_size - (lea_src_size % flt_len)) % 2 != 0 %}
          /* set the aligned position to be zeros */
          lea_src[_LEA_SRC_SIZE] = 0;
          lea_flt[_LEA_SRC_SIZE] = 0;
          {%- endif %}
          {%- endif %}

          switch (intermittent_status[COMPUTE_SWITCH]) {
          case MAC_PREPARE: {
            /* assemble input to a matrix in mac_buffer */
            {%- if (in_ch_flt_len % (lea_src_size - (lea_src_size % flt_len))) != 0 %}
            for (uint16_t i = 0; i < _LEA_REMAIN_SIZE_CHANNEL_CNT; ++i) {
            {%- else %}
            for (uint16_t i = 0; i < _LEA_SRC_SIZE_CHANNEL_CNT; ++i) {
            {%- endif %}
              {%- if has_adaptive_gen_mem and flt_col_size < adaptive_gen_mem_size %}
              uint16_t tmp_input_row_pos = tmp_channel_pos;
              {%- else %}
              uintptr_t tmp_input_row_addr = tmp_channel_addr;
              {%- endif %}
              for (uint16_t k = 0; k < kernel_row_size; ++k) {
                {%- if has_adaptive_gen_mem and flt_col_size < adaptive_gen_mem_size %}
                s = tmp_input_row_pos;
                {%- for n in range(flt_col_size) %}
                lea_src[mac_buffer_pos] = input->data[s];
                s++;
                mac_buffer_pos++;
                {%- endfor %}

                tmp_input_row_pos += input_line_size;
                {%- else %}
                DMA_makeTransfer(tmp_input_row_addr, mac_buffer_addr, kernel_col_size);

                tmp_input_row_addr += input_line_size_offset;
                mac_buffer_addr += flt_addr_col_offset;
                {%- endif %}
              }
              {%- if has_adaptive_gen_mem and flt_col_size < adaptive_gen_mem_size %}
              tmp_channel_pos += input_len;
              {%- else %}
              tmp_channel_addr += input_channel_offset;
              {%- endif %}
            }

            DMA_makeTransfer(lea_src_addr, intermittent_mac_buffer_addr, mac_size)
            VOLATILE_WRITE(MAC_COMPUTE, COMPUTE_SWITCH);
          }
          case MAC_COMPUTE: {
            tmp_out_pos = out_pos + intermittent_status[COMPUTE_OUT_CH] * output_len;
            {%- if in_ch_flt_len > (lea_src_size - (lea_src_size % flt_len)) %}
            {%- if (in_ch_flt_len % (lea_src_size - (lea_src_size % flt_len))) != 0 %}
            mac_size = _LEA_REMAIN_SIZE;
            {%- if lea_opt %}
            lea_mac_params->vectorSize = lea_mac_remain_size_aligned;
            {%- else %}
            mac_params.length = lea_mac_remain_size_aligned;
            {%- endif %}

            {%- else %}
            mac_size = _LEA_SRC_SIZE;
            {%- if lea_opt %}
            lea_mac_params->vectorSize = lea_mac_size_aligned;
            {%- else %}
            mac_params.length = lea_mac_size_aligned;
            {%- endif %}
            {%- endif %}
            {%- endif %}
            for (uint16_t j = intermittent_status[COMPUTE_OUT_CH]; j < out_channels; ++j) {
              DMA_makeTransfer(flt_mac_addr, flt_lea_addr, mac_size);
              {% if lea_opt %}
              new_mac_q15(lea_src, lea_flt);
              {%- else %}
              msp_mac_q15(&mac_params, lea_src, lea_flt, lea_res);
              {%- endif %}

              int16_t mac_out = (int16_t)(lea_res[0] >> 16);
              uint16_t next_j = j + 1;
              DOUBLE_BUFFER_ASSIGN(next_j, COMPUTE_OUT_CH, mac_out, output->data[tmp_out_pos]);

              flt_mac_addr += flt_channel_offset;
              tmp_out_pos += output_len;
            }

            VOLATILE_WRITE(MAC_END, COMPUTE_SWITCH);
          }
          case MAC_END:
            {%- if (in_ch_flt_len % (lea_src_size - (lea_src_size % flt_len))) != 0 %}
            flt_tmp_addr += flt_channel_remain_offset;
            {%- else %}
            flt_tmp_addr += flt_channel_src_offset;
            {% endif %}
            VOLATILE_WRITE(0, COMPUTE_OUT_CH);
          }
          {%- if (in_ch_flt_len % (lea_src_size - (lea_src_size % flt_len))) != 0 %}
          DOUBLE_BUFFER_ASSIGN(_LEA_REMAIN_SIZE, COMPUTE_IN_CH, MAC_PREPARE, intermittent_status[COMPUTE_SWITCH]);
          {%- else %}
          DOUBLE_BUFFER_ASSIGN(_LEA_SRC_SIZE, COMPUTE_IN_CH, MAC_PREPARE, intermittent_status[COMPUTE_SWITCH]);
          {%- endif %}
        {%- if in_ch_flt_len > (lea_src_size - (lea_src_size % flt_len)) %}
        }
        {%- endif %}

        {%- if in_ch_flt_len > (lea_src_size - (lea_src_size % flt_len)) %}

  /*************************************************************
  * Do the rest of MAC
  ************************************************************/
        {%- if (in_ch_flt_len % (lea_src_size - (lea_src_size % flt_len))) != 0 %}
        {%- if (lea_src_size - (lea_src_size % flt_len)) % 2 != 0 %}
        /* set the aligned position to be zeros */
        lea_src[_LEA_SRC_SIZE] = 0;
        lea_flt[_LEA_SRC_SIZE] = 0;
        {%- endif %}
        {%- endif %}

        mac_size = _LEA_SRC_SIZE;
        {%- if lea_opt %}
        lea_mac_params->vectorSize = lea_mac_size_aligned;
        {%- else %}
        mac_params.length = lea_mac_size_aligned;
        {%- endif %}

        uint16_t ch_num = intermittent_status[COMPUTE_IN_CH] / _LEA_SRC_SIZE;
        if (intermittent_status[COMPUTE_SWITCH] == MAC_COMPUTE) {
          ch_num++;
        }
        {%- if (in_ch_flt_len % (lea_src_size - (lea_src_size % flt_len))) != 0 %}
        uint16_t input_pos = (_LEA_REMAIN_SIZE_CHANNEL_CNT + _LEA_SRC_SIZE_CHANNEL_CNT * ch_num) * input_len;
        {%- else %}
        uint16_t input_pos = _LEA_SRC_SIZE_CHANNEL_CNT * ch_num * input_len;
        {%- endif %}
        {%- if has_adaptive_gen_mem and flt_col_size < adaptive_gen_mem_size %}
        uint16_t tmp_channel_pos = tmp_input_pos + input_pos;
        {%- else %}
        uintptr_t tmp_channel_addr = tmp_input_addr + input_pos * sizeof(int16_t);
        {%- endif %}
        for (uint16_t l = intermittent_status[COMPUTE_IN_CH]; l < _MAC_LEN; l += _LEA_SRC_SIZE) {
          uintptr_t flt_mac_addr = flt_tmp_addr + intermittent_status[COMPUTE_OUT_CH] * flt_channel_offset;
          tmp_out_pos = out_pos + intermittent_status[COMPUTE_OUT_CH] * output_len;
          {%- if has_adaptive_gen_mem and flt_col_size < adaptive_gen_mem_size %}
          mac_buffer_pos = 0;
          {%- else %}
          mac_buffer_addr = lea_src_addr;
          {%- endif %}

          switch (intermittent_status[COMPUTE_SWITCH]) {
          case MAC_PREPARE: {
            /* assemble input to a matrix in mac_buffer */
            for (uint16_t i = 0; i < _LEA_SRC_SIZE_CHANNEL_CNT; ++i) {
              {%- if has_adaptive_gen_mem and flt_col_size < adaptive_gen_mem_size %}
              uint16_t tmp_input_row_pos = tmp_channel_pos;
              {%- else %}
              uintptr_t tmp_input_row_addr = tmp_channel_addr;
              {%- endif %}
              for (uint16_t k = 0; k < kernel_row_size; ++k) {
                {%- if has_adaptive_gen_mem and flt_col_size < adaptive_gen_mem_size %}
                s = tmp_input_row_pos;
                {%- for n in range(flt_col_size) %}
                lea_src[mac_buffer_pos] = input->data[s];
                s++;
                mac_buffer_pos++;
                {%- endfor %}

                tmp_input_row_pos += input_line_size;
                {%- else %}
                DMA_makeTransfer(tmp_input_row_addr, mac_buffer_addr, kernel_col_size);

                tmp_input_row_addr += input_line_size_offset;
                mac_buffer_addr += flt_addr_col_offset;
                {%- endif %}
              }
              {%- if has_adaptive_gen_mem and flt_col_size < adaptive_gen_mem_size %}
              tmp_channel_pos += input_len;
              {%- else %}
              tmp_channel_addr += input_channel_offset;
              {%- endif %}
            }

            DMA_makeTransfer(lea_src_addr, intermittent_mac_buffer_addr, mac_size)
            VOLATILE_WRITE(MAC_COMPUTE, COMPUTE_SWITCH);
          }
          case MAC_COMPUTE: {
            for (uint16_t j = intermittent_status[COMPUTE_OUT_CH]; j < out_channels; ++j) {
              DMA_makeTransfer(flt_mac_addr, flt_lea_addr, mac_size);
              {% if lea_opt %}
              new_mac_q15(lea_src, lea_flt);
              {%- else %}
              msp_mac_q15(&mac_params, lea_src, lea_flt, lea_res);
              {%- endif %}

              int16_t mac_out = (int16_t)(lea_res[0] >> 16);
              mac_out =  __saturated_add_q15(mac_out, output->data[tmp_out_pos]);
              uint16_t next_j = j + 1;
              DOUBLE_BUFFER_ASSIGN(next_j, COMPUTE_OUT_CH, mac_out, output->data[tmp_out_pos]);

              flt_mac_addr += flt_channel_offset;
              tmp_out_pos += output_len;
            }

            VOLATILE_WRITE(MAC_END, COMPUTE_SWITCH);
          }
          case MAC_END:
            flt_tmp_addr += flt_channel_src_offset;
            VOLATILE_WRITE(0, COMPUTE_OUT_CH);
          }

          uint16_t next_l = l + _LEA_SRC_SIZE;
          DOUBLE_BUFFER_ASSIGN(next_l, COMPUTE_IN_CH, MAC_PREPARE, intermittent_status[COMPUTE_SWITCH]);
        }
        {%- endif %}

        uint16_t next_n = n + 1;
        DOUBLE_BUFFER_ASSIGN(next_n, COMPUTE_IO_COL, 0, intermittent_status[COMPUTE_IN_CH]);

        {%- if has_adaptive_gen_mem and flt_col_size < adaptive_gen_mem_size %}
        tmp_input_pos += _STRIDE_COL_SIZE;
        {%- else %}
        tmp_input_addr += _STRIDE_COL_OFFSET;
        {%- endif %}
        out_pos++;
      }

      uint16_t next_m = m + 1;
      DOUBLE_BUFFER_ASSIGN(next_m, COMPUTE_IO_ROW, 0, intermittent_status[COMPUTE_IO_COL]);

      {%- if has_adaptive_gen_mem and flt_col_size < adaptive_gen_mem_size %}
      input_fram_pos += input_line_strided_size;
      {%- else %}
      input_fram_addr += input_line_size_strided_offset;
      {%- endif %}
    }

    VOLATILE_WRITE(INTERMITTENT_{{ layer_name }}_BIAS, COMPUTE_CK);
  }

  /* add bias and left shift */
  if (intermittent_status[COMPUTE_CK] == INTERMITTENT_{{ layer_name }}_BIAS) {
    _q15* lea_add = lea_src;
    uint16_t add_size = _LEA_ADD_SIZE;
    uintptr_t lea_add_addr = (uintptr_t)lea_add;

    /* Recover loop variables. We use COMPUTE_IN_CH as it will be zero when the start of this */
    if (intermittent_status[COMPUTE_IN_CH] & DOUBLE_BUFFER_WRITE) {
      uint16_t idx = intermittent_status[COMPUTE_IN_CH] & DOUBLE_BUFFER_COMPLETE;
      VOLATILE_WRITE(intermittent_buffer[0], COMPUTE_IO_COL);
      VOLATILE_WRITE(idx, COMPUTE_IN_CH);
    }

    if (intermittent_status[COMPUTE_IO_COL] & DOUBLE_BUFFER_WRITE) {
      /* Start transferring to output buffer. Recover from temporary buffer */
      uint16_t line = intermittent_status[COMPUTE_IO_COL] & DOUBLE_BUFFER_COMPLETE;
      uint16_t size = line;
      if (size > lea_remain_size) {
        size = add_size;
      }
      uintptr_t addr = (uintptr_t)(output->data) + \
        (intermittent_status[COMPUTE_IN_CH] * output_len + (line - size)) * sizeof(int16_t);

      DMA_makeTransfer(intermittent_buffer_addr, addr, size);

      VOLATILE_WRITE(line, COMPUTE_IO_COL);
    }

    if (intermittent_status[COMPUTE_IO_COL] >= output_len) {
      uint16_t next_idx = intermittent_status[COMPUTE_IN_CH] + 1;
      DOUBLE_BUFFER_ASSIGN(next_idx, COMPUTE_IN_CH, 0, intermittent_status[COMPUTE_IO_COL]);
    }

    uintptr_t output_fram_addr = (uintptr_t)(output->data) + \
      (intermittent_status[COMPUTE_IN_CH] * output_len + \
        intermittent_status[COMPUTE_IO_COL]) * sizeof(int16_t);

    for (uint16_t i = intermittent_status[COMPUTE_IN_CH]; i < out_channels; ++i) {
      {%- if lea_opt %}
      set_offset(bias->data[i]);
      {%- else %}
      offset_params.offset = bias->data[i];
      {%- endif %}

      {%- if (global_mem_buffer and (out_len % lea_buffer_size) != 0) or ((not global_mem_buffer) and (out_len % lea_src_size) != 0) %}
      {%- if (global_mem_buffer and out_len >= lea_buffer_size) or ((not global_mem_buffer) and out_len >= lea_src_size) %}
      if (intermittent_status[COMPUTE_IO_COL] == 0) {
      {%- endif %}
        {%- if lea_opt %}
        lea_offset_params->vectorSize = lea_remain_size_aligned;
        {%- if qf > 0 %}
        lea_add_params->vectorSize = lea_remain_size_aligned;
        {%- endif %}
        {%- else %}
        offset_params.length = lea_remain_size_aligned;
        {%- if qf > 0 %}
        add_params.length = lea_remain_size_aligned;
        {%- endif %}
        {%- endif %}

        DMA_makeTransfer(output_fram_addr, lea_add_addr, lea_remain_size);
        {% for i in range(qf) %}
        {%- if lea_opt %}
        new_add_q15(lea_add, lea_add, lea_add);
        {%- else %}
        msp_add_q15(&add_params, lea_add, lea_add, lea_add);
        {%- endif %}
        {%- endfor %}
        {%- if lea_opt %}
        new_offset_q15(lea_add, lea_add);
        {%- else %}
        msp_offset_q15(&offset_params, lea_add, lea_add);
        {%- endif %}

        uint16_t next_r = lea_remain_size;
        DOUBLE_BUFFER_TRANSFER(next_r, COMPUTE_IO_COL, lea_add_addr, output_fram_addr, lea_remain_size);

        output_fram_addr += output_remain_size_offset;
      {%- if (global_mem_buffer and out_len >= lea_buffer_size) or ((not global_mem_buffer) and out_len >= lea_src_size) %}
      }
      {%- endif %}
      {%- endif %}

      {%- if (global_mem_buffer and out_len >= lea_buffer_size) or ((not global_mem_buffer) and out_len >= lea_src_size) %}

      {%- if lea_opt %}
      lea_offset_params->vectorSize = add_size;
      {%- if qf > 0 %}
      lea_add_params->vectorSize = add_size;
      {%- endif %}
      {%- else %}
      offset_params.length = add_size;
      {%- if qf > 0 %}
      add_params.length = add_size;
      {%- endif %}
      {%- endif %}

      for (uint16_t j = intermittent_status[COMPUTE_IO_COL]; j < output_len; j += add_size) {
        DMA_makeTransfer(output_fram_addr, lea_add_addr, add_size);
        {% for i in range(qf) %}
        {%- if lea_opt %}
        new_add_q15(lea_add, lea_add, lea_add);
        {%- else %}
        msp_add_q15(&add_params, lea_add, lea_add, lea_add);
        {%- endif %}
        {%- endfor %}
        {%- if lea_opt %}
        new_offset_q15(lea_add, lea_add);
        {%- else %}
        msp_offset_q15(&offset_params, lea_add, lea_add);
        {%- endif %}

        uint16_t next_r = j + add_size;
        DOUBLE_BUFFER_TRANSFER(next_r, COMPUTE_IO_COL, lea_add_addr, output_fram_addr, add_size);

        output_fram_addr += output_lea_min_size_offset;
      }
      {%- endif %}
      uint16_t next_i = i + 1;
      DOUBLE_BUFFER_ASSIGN(next_i, COMPUTE_IN_CH, 0, intermittent_status[COMPUTE_IO_COL]);
    }

    VOLATILE_WRITE(INTERMITTENT_{{ layer_name }}_EXIT, COMPUTE_CK);
  }

  if (intermittent_status[COMPUTE_CK] == INTERMITTENT_{{ layer_name }}_EXIT) {
    {%- if lea_opt %}
    offset_clear();
    add_clear();
    mac_clear();
    {%- endif %}
    intermittent_status[COMPUTE_SWITCH] = PAD_START;
    intermittent_status[COMPUTE_IO_COL] = 0;
    intermittent_status[COMPUTE_IO_ROW] = 0;
    intermittent_status[COMPUTE_IN_CH] = 0;
    intermittent_status[COMPUTE_OUT_CH] = 0;
  }
}